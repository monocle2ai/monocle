import asyncio
import logging
import os

import bs4
import pytest
from common.custom_exporter import CustomConsoleSpanExporter
from common.helpers import (
    find_span_by_type,
    find_spans_by_type,
    validate_inference_span_events,
    verify_inference_span,
)
from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import (
    AzureChatOpenAI,
    OpenAIEmbeddings,
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from monocle_apptrace.instrumentation.common.instrumentor import setup_monocle_telemetry
from opentelemetry.sdk.trace.export import BatchSpanProcessor

logger = logging.getLogger(__name__)
custom_exporter = CustomConsoleSpanExporter()


@pytest.fixture(scope="module")
def setup():
    try:
        instrumentor = setup_monocle_telemetry(
            workflow_name="langchain_app_1",
            span_processors=[
                BatchSpanProcessor(
                    custom_exporter, max_queue_size=1, max_export_batch_size=1
                )
            ],
            wrapper_methods=[],
        )
        yield
    finally:
        # Clean up instrumentor to avoid global state leakage
        if instrumentor and instrumentor.is_instrumented_by_opentelemetry:
            instrumentor.uninstrument()


# llm = ChatMistralAI(
#     model="mistral-large-latest",
#     temperature=0.7,
# )


@pytest.mark.integration()
def test_langchain_sample(setup):
    # llm = OpenAI(model="gpt-3.5-turbo-instruct")
    llm = AzureChatOpenAI(
        # engine=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT"),
        azure_deployment=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT"),
        api_key=os.environ.get("AZURE_OPENAI_API_KEY"),
        api_version=os.environ.get("AZURE_OPENAI_API_VERSION"),
        azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
        temperature=0.1,
        # model="gpt-4",
        model="gpt-4o-mini",
    )
    # Load, chunk and index the contents of the blog.
    loader = WebBaseLoader(
        web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                class_=("post-content", "post-title", "post-header")
            )
        ),
    )
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

    # Retrieve and generate using the relevant snippets of the blog.
    retriever = vectorstore.as_retriever()
    prompt = hub.pull("rlm/rag-prompt")

    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    custom_exporter.reset()  # Remove spans generated by OpenAIEmbeddings() during vector operations
    result = rag_chain.invoke("What is Task Decomposition?")
    logger.info(result)

    asyncio.sleep(5)  # Allow time for spans to be captured

    spans = custom_exporter.get_captured_spans()

    assert len(spans) > 0, "No spans captured for the LangChain Anthropic sample"
    retrival_span = None
    for span in spans:
        span_attributes = span.attributes
        if (
            "span.type" in span_attributes
            and span_attributes["span.type"] == "retrieval"
        ):
            # Assertions for all retrieval attributes
            assert span_attributes["entity.1.name"] == "Chroma"
            assert span_attributes["entity.1.type"] == "vectorstore.Chroma"
            assert "entity.1.deployment" in span_attributes
            assert span_attributes["entity.2.name"] == "text-embedding-ada-002"
            assert (
                span_attributes["entity.2.type"]
                == "model.embedding.text-embedding-ada-002"
            )
            assert not span.name.lower().startswith("openai")
            retrival_span = span
    assert retrival_span is not None, "Expected to find retrieval span"
    workflow_span = None

    inference_spans = find_spans_by_type(spans, "inference")
    if not inference_spans:
        # Also check for inference.framework spans
        inference_spans = find_spans_by_type(spans, "inference.framework")

    assert len(inference_spans) > 0, "Expected to find at least one inference span"

    # Verify each inference span
    for span in inference_spans:
        verify_inference_span(
            span=span,
            entity_type="inference.azure_openai",
            model_name="gpt-4o-mini",
            model_type="model.llm.gpt-4o-mini",
            check_metadata=True,
            check_input_output=True,
        )
    assert (
        len(inference_spans) == 1
    ), "Expected exactly one inference span for the LLM call"

    # Validate events using the generic function with regex patterns
    validate_inference_span_events(
        span=inference_spans[0],
        expected_event_count=3,
        input_patterns=[r"^\{\"human\": \".+\"\}$"],  # Pattern for human message
        output_pattern=r"^\{\"ai\": \".+\"\}$",  # Pattern for AI response
        metadata_requirements={
            "temperature": float,
            "completion_tokens": int,
            "prompt_tokens": int,
            "total_tokens": int,
        },
    )

    workflow_span = find_span_by_type(spans, "workflow")

    assert workflow_span is not None, "Expected to find workflow span"

    assert workflow_span.attributes["span.type"] == "workflow"
    assert workflow_span.attributes["entity.1.name"] == "langchain_app_1"
    assert workflow_span.attributes["entity.1.type"] == "workflow.langchain"


if __name__ == "__main__":
    pytest.main([__file__, "-s", "--tb=short"])

# {
#     "name": "openai.resources.embeddings.Embeddings",
#     "context": {
#         "trace_id": "0xdba6239de9d9e1ea2b2c44de9594f173",
#         "span_id": "0x4f2b4d9151596235",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x0fc0b64f3d295008",
#     "start_time": "2025-07-02T15:45:58.133847Z",
#     "end_time": "2025-07-02T15:45:59.946091Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "workflow.name": "langchain_app_1",
#         "span.type": "embedding",
#         "entity.1.name": "text-embedding-ada-002",
#         "entity.1.type": "model.embedding.text-embedding-ada-002",
#         "entity.count": 1
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:45:59.913269Z",
#             "attributes": {}
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:45:59.946029Z",
#             "attributes": {
#                 "response": "index=0, embedding=[0.00405939482152462, 0.00843347143381834, -0.005395044106990099, -0.024195531383..."
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "workflow",
#     "context": {
#         "trace_id": "0xdba6239de9d9e1ea2b2c44de9594f173",
#         "span_id": "0x0fc0b64f3d295008",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": null,
#     "start_time": "2025-07-02T15:45:58.133785Z",
#     "end_time": "2025-07-02T15:45:59.946144Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "span.type": "workflow",
#         "entity.1.name": "langchain_app_1",
#         "entity.1.type": "workflow.generic",
#         "entity.2.type": "app_hosting.generic",
#         "entity.2.name": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "openai.resources.embeddings.Embeddings",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xc79c17bfa98c3fe9",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x8c61a68f8cabc420",
#     "start_time": "2025-07-02T15:46:00.664382Z",
#     "end_time": "2025-07-02T15:46:01.060072Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "workflow.name": "langchain_app_1",
#         "span.type": "embedding.modelapi"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.vectorstores.base.VectorStoreRetriever",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x8c61a68f8cabc420",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0xd6146842adad9361",
#     "start_time": "2025-07-02T15:46:00.663340Z",
#     "end_time": "2025-07-02T15:46:01.064338Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3045",
#         "workflow.name": "langchain_app_1",
#         "span.type": "retrieval",
#         "entity.1.name": "Chroma",
#         "entity.1.type": "vectorstore.Chroma",
#         "entity.1.deployment": "localhost:50052",
#         "entity.2.name": "text-embedding-ada-002",
#         "entity.2.type": "model.embedding.text-embedding-ada-002",
#         "entity.count": 2
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:46:01.064317Z",
#             "attributes": {
#                 "input": "What is Task Decomposition?"
#             }
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:46:01.064330Z",
#             "attributes": {
#                 "response": "Component One: Planning#\nA complicated task usually involves many steps. An agent needs to know what..."
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.runnables.base.RunnableSequence",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xd6146842adad9361",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:00.662991Z",
#     "end_time": "2025-07-02T15:46:01.064642Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3758",
#         "workflow.name": "langchain_app_1",
#         "span.type": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.prompts.chat.ChatPromptTemplate",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x42fb15c055446982",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:01.065082Z",
#     "end_time": "2025-07-02T15:46:01.065449Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047",
#         "workflow.name": "langchain_app_1",
#         "span.type": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_openai.chat_models.azure.AzureChatOpenAI",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x7b834745c089e9ca",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:01.065711Z",
#     "end_time": "2025-07-02T15:46:03.025715Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047",
#         "workflow.name": "langchain_app_1",
#         "span.type": "inference.framework",
#         "entity.1.type": "inference.azure_openai",
#         "entity.1.provider_name": "okahu-openai-dev.openai.azure.com",
#         "entity.1.deployment": "kshitiz-gpt",
#         "entity.1.inference_endpoint": "https://okahu-openai-dev.openai.azure.com/",
#         "entity.2.name": "gpt-4o-mini",
#         "entity.2.type": "model.llm.gpt-4o-mini",
#         "entity.count": 2
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:46:03.025669Z",
#             "attributes": {
#                 "input": [
#                     "{\"human\": \"You are an assistant for question-answering tasks. Use the following pieces of retrieved ... \"}"
#                 ]
#             }
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:46:03.025692Z",
#             "attributes": {
#                 "response": "{\"ai\": \"Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps, allowing for easier execution and understanding. This approach can be implemented through various methods such as simple prompting, task-specific instructions, or relying on external classical planners. By decomposing tasks, agents can effectively plan ahead and improve performance on challenging tasks.\"}"
#             }
#         },
#         {
#             "name": "metadata",
#             "timestamp": "2025-07-02T15:46:03.025706Z",
#             "attributes": {
#                 "temperature": 0.1,
#                 "completion_tokens": 66,
#                 "prompt_tokens": 684,
#                 "total_tokens": 750
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "workflow",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xd6c3f2a89da89f97",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": null,
#     "start_time": "2025-07-02T15:46:00.656284Z",
#     "end_time": "2025-07-02T15:46:03.026456Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/tests/integration/test_langchain_sample.py:87",
#         "span.type": "workflow",
#         "entity.1.name": "langchain_app_1",
#         "entity.1.type": "workflow.langchain",
#         "entity.2.type": "app_hosting.generic",
#         "entity.2.name": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
