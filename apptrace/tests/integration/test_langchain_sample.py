import logging
import os
import time

import bs4
import pytest
from common.custom_exporter import CustomConsoleSpanExporter
from common.helpers import (
    find_span_by_type,
    find_spans_by_type,
    validate_inference_span_events,
    verify_inference_span,
)
from langchain import hub
from langchain_chroma import Chroma
from langchain_community.document_loaders import WebBaseLoader
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import (
    AzureChatOpenAI,
    OpenAIEmbeddings,
)
from langchain_text_splitters import RecursiveCharacterTextSplitter
from monocle_apptrace.instrumentation.common.instrumentor import setup_monocle_telemetry
from opentelemetry.sdk.trace.export import BatchSpanProcessor

logger = logging.getLogger(__name__)
custom_exporter = CustomConsoleSpanExporter()


@pytest.fixture(scope="module")
def setup():
    try:
        instrumentor = setup_monocle_telemetry(
            workflow_name="langchain_app_1",
            span_processors=[
                BatchSpanProcessor(
                    custom_exporter, max_queue_size=1, max_export_batch_size=1
                )
            ],
            wrapper_methods=[],
        )
        yield custom_exporter
    finally:
        # Clean up instrumentor to avoid global state leakage
        if instrumentor and instrumentor.is_instrumented_by_opentelemetry:
            instrumentor.uninstrument()


# llm = ChatMistralAI(
#     model="mistral-large-latest",
#     temperature=0.7,
# )


def test_langchain_sample(setup):
    # llm = OpenAI(model="gpt-3.5-turbo-instruct")
    llm = AzureChatOpenAI(
        # engine=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT"),
        azure_deployment=os.environ.get("AZURE_OPENAI_API_DEPLOYMENT"),
        api_key=os.environ.get("AZURE_OPENAI_API_KEY"),
        api_version=os.environ.get("AZURE_OPENAI_API_VERSION"),
        azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT"),
        temperature=0.1,
        # model="gpt-4",
        model="gpt-4o-mini",
    )
    # Load, chunk and index the contents of the blog.
    loader = WebBaseLoader(
        web_paths=("https://lilianweng.github.io/posts/2023-06-23-agent/",),
        bs_kwargs=dict(
            parse_only=bs4.SoupStrainer(
                class_=("post-content", "post-title", "post-header")
            )
        ),
    )
    docs = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())

    # Retrieve and generate using the relevant snippets of the blog.
    retriever = vectorstore.as_retriever()
    prompt = hub.pull("rlm/rag-prompt")

    def format_docs(docs):
        return "\n\n".join(doc.page_content for doc in docs)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )

    setup.reset()  # Remove spans generated by OpenAIEmbeddings() during vector operations
    result = rag_chain.invoke("What is Task Decomposition?")
    logger.info(result)

    time.sleep(2)  # Allow time for spans to be captured

    spans = setup.get_captured_spans()
    print(f"Captured spans: {len(spans)}")

    assert len(spans) > 0, "No spans captured for the LangChain Anthropic sample"
    found_retrieval_span = False
    retrieval_spans = find_spans_by_type(spans, "retrieval")
    assert len(retrieval_spans) > 0, "Expected to find retrieval span"
    print(f"Found span: {retrieval_spans[0].attributes.get('span.type')}")
    print(f"Total retrieval spans found: {len(retrieval_spans)}")
    
    
    # Verify each retrieval span
    for span in retrieval_spans:
        span_attributes = span.attributes
        if (
            "span.type" in span_attributes
            and span_attributes["span.type"] == "retrieval"
        ):
            found_retrieval_span = True
            # Assertions for all retrieval attributes
            assert span_attributes["entity.1.name"] == "Chroma"
            assert span_attributes["entity.1.type"] == "vectorstore.Chroma"
            assert "entity.1.deployment" in span_attributes
            assert span_attributes["entity.2.name"] == "text-embedding-ada-002"
            assert (
                span_attributes["entity.2.type"]
                == "model.embedding.text-embedding-ada-002"
            )
            assert not span.name.lower().startswith("openai")
            
    assert found_retrieval_span, "Expected to find retrieval span"
    workflow_span = None

    inference_spans = find_spans_by_type(spans, "inference")
    if not inference_spans:
        # Also check for inference.framework spans
        inference_spans = find_spans_by_type(spans, "inference.framework")

    assert len(inference_spans) > 0, "Expected to find at least one inference span"

    # Verify each inference span
    for span in inference_spans:
        verify_inference_span(
            span=span,
            entity_type="inference.azure_openai",
            model_name="gpt-4o-mini",
            model_type="model.llm.gpt-4o-mini",
            check_metadata=True,
            check_input_output=True,
        )
    assert (
        len(inference_spans) == 1
    ), "Expected exactly one inference span for the LLM call"

    # Validate events using the generic function with regex patterns
    validate_inference_span_events(
        span=inference_spans[0],
        expected_event_count=3,
        input_patterns=[r"^\{\"human\": \".+\"\}$"],  # Pattern for human message
        output_pattern=r"^\{\"ai\": \".+\"\}$",  # Pattern for AI response
        metadata_requirements={
            "temperature": float,
            "completion_tokens": int,
            "prompt_tokens": int,
            "total_tokens": int,
        },
    )

    workflow_span = find_span_by_type(spans, "workflow")

    assert workflow_span is not None, "Expected to find workflow span"

    assert workflow_span.attributes["span.type"] == "workflow"
    assert workflow_span.attributes["entity.1.name"] == "langchain_app_1"
    assert workflow_span.attributes["entity.1.type"] in ["workflow.langchain","workflow.openai"]


if __name__ == "__main__":
    pytest.main([__file__, "-s", "--tb=short"])

# {
#     "name": "openai.resources.embeddings.Embeddings",
#     "context": {
#         "trace_id": "0xdba6239de9d9e1ea2b2c44de9594f173",
#         "span_id": "0x4f2b4d9151596235",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x0fc0b64f3d295008",
#     "start_time": "2025-07-02T15:45:58.133847Z",
#     "end_time": "2025-07-02T15:45:59.946091Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "workflow.name": "langchain_app_1",
#         "span.type": "embedding",
#         "entity.1.name": "text-embedding-ada-002",
#         "entity.1.type": "model.embedding.text-embedding-ada-002",
#         "entity.count": 1
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:45:59.913269Z",
#             "attributes": {}
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:45:59.946029Z",
#             "attributes": {
#                 "response": "index=0, embedding=[0.00405939482152462, 0.00843347143381834, -0.005395044106990099, -0.024195531383..."
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "workflow",
#     "context": {
#         "trace_id": "0xdba6239de9d9e1ea2b2c44de9594f173",
#         "span_id": "0x0fc0b64f3d295008",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": null,
#     "start_time": "2025-07-02T15:45:58.133785Z",
#     "end_time": "2025-07-02T15:45:59.946144Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "span.type": "workflow",
#         "entity.1.name": "langchain_app_1",
#         "entity.1.type": "workflow.generic",
#         "entity.2.type": "app_hosting.generic",
#         "entity.2.name": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "openai.resources.embeddings.Embeddings",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xc79c17bfa98c3fe9",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x8c61a68f8cabc420",
#     "start_time": "2025-07-02T15:46:00.664382Z",
#     "end_time": "2025-07-02T15:46:01.060072Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_openai/embeddings/base.py:478",
#         "workflow.name": "langchain_app_1",
#         "span.type": "embedding.modelapi"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.vectorstores.base.VectorStoreRetriever",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x8c61a68f8cabc420",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0xd6146842adad9361",
#     "start_time": "2025-07-02T15:46:00.663340Z",
#     "end_time": "2025-07-02T15:46:01.064338Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3045",
#         "workflow.name": "langchain_app_1",
#         "span.type": "retrieval",
#         "entity.1.name": "Chroma",
#         "entity.1.type": "vectorstore.Chroma",
#         "entity.1.deployment": "localhost:50052",
#         "entity.2.name": "text-embedding-ada-002",
#         "entity.2.type": "model.embedding.text-embedding-ada-002",
#         "entity.count": 2
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:46:01.064317Z",
#             "attributes": {
#                 "input": "What is Task Decomposition?"
#             }
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:46:01.064330Z",
#             "attributes": {
#                 "response": "Component One: Planning#\nA complicated task usually involves many steps. An agent needs to know what..."
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.runnables.base.RunnableSequence",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xd6146842adad9361",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:00.662991Z",
#     "end_time": "2025-07-02T15:46:01.064642Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3758",
#         "workflow.name": "langchain_app_1",
#         "span.type": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_core.prompts.chat.ChatPromptTemplate",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x42fb15c055446982",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:01.065082Z",
#     "end_time": "2025-07-02T15:46:01.065449Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047",
#         "workflow.name": "langchain_app_1",
#         "span.type": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "langchain_openai.chat_models.azure.AzureChatOpenAI",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0x7b834745c089e9ca",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": "0x4a966648defd3921",
#     "start_time": "2025-07-02T15:46:01.065711Z",
#     "end_time": "2025-07-02T15:46:03.025715Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/.venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:3047",
#         "workflow.name": "langchain_app_1",
#         "span.type": "inference.framework",
#         "entity.1.type": "inference.azure_openai",
#         "entity.1.provider_name": "okahu-openai-dev.openai.azure.com",
#         "entity.1.deployment": "kshitiz-gpt",
#         "entity.1.inference_endpoint": "https://okahu-openai-dev.openai.azure.com/",
#         "entity.2.name": "gpt-4o-mini",
#         "entity.2.type": "model.llm.gpt-4o-mini",
#         "entity.count": 2
#     },
#     "events": [
#         {
#             "name": "data.input",
#             "timestamp": "2025-07-02T15:46:03.025669Z",
#             "attributes": {
#                 "input": [
#                     "{\"human\": \"You are an assistant for question-answering tasks. Use the following pieces of retrieved ... \"}"
#                 ]
#             }
#         },
#         {
#             "name": "data.output",
#             "timestamp": "2025-07-02T15:46:03.025692Z",
#             "attributes": {
#                 "response": "{\"ai\": \"Task Decomposition is a technique used to break down complex tasks into smaller and simpler steps, allowing for easier execution and understanding. This approach can be implemented through various methods such as simple prompting, task-specific instructions, or relying on external classical planners. By decomposing tasks, agents can effectively plan ahead and improve performance on challenging tasks.\"}"
#             }
#         },
#         {
#             "name": "metadata",
#             "timestamp": "2025-07-02T15:46:03.025706Z",
#             "attributes": {
#                 "temperature": 0.1,
#                 "completion_tokens": 66,
#                 "prompt_tokens": 684,
#                 "total_tokens": 750
#             }
#         }
#     ],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
# {
#     "name": "workflow",
#     "context": {
#         "trace_id": "0x7c2fc98d491008c263d22a6eb0984cbb",
#         "span_id": "0xd6c3f2a89da89f97",
#         "trace_state": "[]"
#     },
#     "kind": "SpanKind.INTERNAL",
#     "parent_id": null,
#     "start_time": "2025-07-02T15:46:00.656284Z",
#     "end_time": "2025-07-02T15:46:03.026456Z",
#     "status": {
#         "status_code": "OK"
#     },
#     "attributes": {
#         "monocle_apptrace.version": "0.4.0",
#         "monocle_apptrace.language": "python",
#         "span_source": "/Users/kshitizvijayvargiya/monocle-ksh/tests/integration/test_langchain_sample.py:87",
#         "span.type": "workflow",
#         "entity.1.name": "langchain_app_1",
#         "entity.1.type": "workflow.langchain",
#         "entity.2.type": "app_hosting.generic",
#         "entity.2.name": "generic"
#     },
#     "events": [],
#     "links": [],
#     "resource": {
#         "attributes": {
#             "service.name": "langchain_app_1"
#         },
#         "schema_url": ""
#     }
# }
